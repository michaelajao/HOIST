{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "\n",
    "def seed_torch(RANDOM_SEED=123):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_torch()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from utils import generate_series, temporal_split\n",
    "from model import HOIST_with_claim\n",
    "from utils import mse,mae,r2,ccc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_mat = pickle.load(open('./data/mob_mat.pkl', 'rb'))\n",
    "distance_mat = pickle.load(open('./data/distance_mat.pkl', 'rb'))\n",
    "covid_tensor = pickle.load(open('./data/covid_tensor.pkl', 'rb'))\n",
    "claim_tensor = pickle.load(open('./data/claim_tensor.pkl', 'rb'))\n",
    "vac_tensor = pickle.load(open('./data/vac_tensor.pkl', 'rb'))\n",
    "hos_tensor = pickle.load(open('./data/hos_tensor.pkl', 'rb'))\n",
    "county_tensor = pickle.load(open('./data/county_tensor.pkl', 'rb'))\n",
    "feat_name = pickle.load(open('./data/feat_name.pkl', 'rb'))\n",
    "date_range = np.array(pickle.load(open('./data/date_range.pkl', 'rb')), dtype=np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_name['vaccination'] = ['tot', '1st', '2nd', 'bst', 'Pfizer_1', 'Pfizer_2', 'Pfizer_b', 'Moderna_1', 'Moderna_2', 'Moderna_b', 'Johnson_1', 'Johnson_b', 'PfizerTS_1', 'PfizerTS_2', 'PfizerTS_b', 'PfizerTS10_1', 'PfizerTS10_2']\n",
    "vac_tensor = vac_tensor[:,:,:len(feat_name['vaccination'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2299\n"
     ]
    }
   ],
   "source": [
    "covid_tensor = np.expand_dims(covid_tensor, axis=2)\n",
    "X = np.concatenate([covid_tensor, claim_tensor, hos_tensor, vac_tensor], axis=2)\n",
    "y = claim_tensor[:, :, 0]\n",
    "X, y = generate_series(X, y, window_size=35, pred_size=28)\n",
    "date_idx = np.expand_dims(date_range, axis=0)\n",
    "date_idx = np.expand_dims(date_idx, axis=2)\n",
    "date_idx, _ = generate_series(date_idx, y, window_size=35, pred_size=28, date=True)\n",
    "\n",
    "range_idx = (y.mean(1)>0)\n",
    "county_tensor = county_tensor[range_idx]\n",
    "y = y[range_idx]\n",
    "X = X[range_idx]\n",
    "print(len(y))\n",
    "mob_mat = mob_mat[range_idx, :][:, range_idx]\n",
    "distance_mat = distance_mat[range_idx, :][:, range_idx]\n",
    "\n",
    "y = np.log(y+1)\n",
    "train_x, val_x, test_x, train_y, val_y, test_y, train_idx, val_idx, test_idx, static, mats, normalize_dict, shuffle_idx = temporal_split(X, y, county_tensor, [mob_mat, distance_mat], 0.2, 0.2, norm='min-max', norm_mat=True)\n",
    "\n",
    "norm_mob = mats[0]\n",
    "norm_dist = mats[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 2.4893, Val Loss: 3.2777, MSE: 22.30, MAE: 3.48\n",
      "Epoch: 100, Train Loss: 0.6828, Val Loss: 0.1121, MSE: 0.76, MAE: 0.63\n",
      "Epoch: 200, Train Loss: 0.6608, Val Loss: 0.0850, MSE: 0.58, MAE: 0.55\n",
      "Best Epoch: 298, Test MSE: 0.70, MAE: 0.62, R2: 0.90, CCC: 0.95\n",
      "Epoch: 0, Train Loss: 2.1303, Val Loss: 2.1597, MSE: 14.70, MAE: 2.95\n",
      "Epoch: 100, Train Loss: 0.6919, Val Loss: 0.1126, MSE: 0.77, MAE: 0.65\n",
      "Epoch: 200, Train Loss: 0.6676, Val Loss: 0.0914, MSE: 0.62, MAE: 0.58\n",
      "Best Epoch: 288, Test MSE: 0.71, MAE: 0.64, R2: 0.90, CCC: 0.95\n",
      "Epoch: 0, Train Loss: 2.1840, Val Loss: 2.9089, MSE: 19.79, MAE: 3.44\n",
      "Epoch: 100, Train Loss: 0.6794, Val Loss: 0.1090, MSE: 0.74, MAE: 0.62\n",
      "Epoch: 200, Train Loss: 0.6677, Val Loss: 0.0960, MSE: 0.65, MAE: 0.60\n",
      "Best Epoch: 271, Test MSE: 0.67, MAE: 0.62, R2: 0.90, CCC: 0.96\n",
      "Epoch: 0, Train Loss: 2.0748, Val Loss: 1.3518, MSE: 9.20, MAE: 2.40\n",
      "Epoch: 100, Train Loss: 0.6877, Val Loss: 0.1226, MSE: 0.83, MAE: 0.65\n",
      "Epoch: 200, Train Loss: 0.6588, Val Loss: 0.0849, MSE: 0.58, MAE: 0.55\n",
      "Best Epoch: 290, Test MSE: 0.66, MAE: 0.60, R2: 0.91, CCC: 0.95\n",
      "Epoch: 0, Train Loss: 2.2924, Val Loss: 1.0857, MSE: 7.39, MAE: 2.19\n",
      "Epoch: 100, Train Loss: 0.6873, Val Loss: 0.1018, MSE: 0.69, MAE: 0.61\n",
      "Epoch: 200, Train Loss: 0.6639, Val Loss: 0.0854, MSE: 0.58, MAE: 0.55\n",
      "Best Epoch: 268, Test MSE: 0.73, MAE: 0.64, R2: 0.90, CCC: 0.95\n"
     ]
    }
   ],
   "source": [
    "mae_ = []\n",
    "mae_exp = []\n",
    "mse_ = []\n",
    "mse_exp = []\n",
    "r2_ = []\n",
    "r2_exp = []\n",
    "ccc_ = []\n",
    "ccc_exp = []\n",
    "for k in range(5):\n",
    "    seed_torch(k)\n",
    "    model = HOIST_with_claim(42, [4,5,5], 128, device).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "    loss_fn = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "    epoch = 300\n",
    "    batch_size = 128\n",
    "    min_loss = 1e99\n",
    "    min_epoch = 0\n",
    "\n",
    "    for i in range(epoch):\n",
    "        epoch_loss = []\n",
    "        val_loss = []\n",
    "        model.train()\n",
    "        for j in range((len(test_x)//batch_size)+1):\n",
    "            batch_x = train_x[j*batch_size:(j+1)*batch_size]\n",
    "            batch_y = train_y[j*batch_size:(j+1)*batch_size]\n",
    "            batch_x = torch.tensor(batch_x).float().to(device)\n",
    "            batch_y = torch.tensor(batch_y).float().to(device).unsqueeze(-1)\n",
    "            batch_static = torch.tensor(static[j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "            batch_mob = torch.tensor(norm_mob[j*batch_size:(j+1)*batch_size,:][:,j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "            batch_dist = torch.tensor(norm_dist[j*batch_size:(j+1)*batch_size,:][:,j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "            batch_mat = torch.cat([batch_mob.unsqueeze(-1), batch_dist.unsqueeze(-1)], dim=2)\n",
    "            cur_static = [batch_static[:, :4], batch_static[:, 4:9], batch_static[:, 9:14], batch_mat]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output, _ = model(batch_x, cur_static)\n",
    "            \n",
    "            N, T, F = batch_y.shape\n",
    "            dist = _[0]\n",
    "            weights = _[1]\n",
    "            y_p = (weights * batch_x).sum(-1).reshape(N,T,1)*output.detach()\n",
    "            y_pi = y_p.reshape(N,1,T)\n",
    "            y_pj = y_p.reshape(1,N,T)\n",
    "            y_k = ((y_pi * y_pj) * dist.reshape(N,N,1)).sum(1).reshape(N,T,1)\n",
    "            ising_loss = loss_fn(y_p+y_k, batch_y).mean(1).mean()\n",
    "            \n",
    "            loss = loss_fn(output, batch_y).mean(1).mean() + ising_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(loss.item())\n",
    "        \n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            for j in range((len(test_x)//batch_size)+1):\n",
    "                batch_x = val_x[j*batch_size:(j+1)*batch_size]\n",
    "                batch_y = val_y[j*batch_size:(j+1)*batch_size]\n",
    "                batch_x = torch.tensor(batch_x).float().to(device)\n",
    "                batch_y = torch.tensor(batch_y).float().to(device).unsqueeze(-1)\n",
    "                batch_static = torch.tensor(static[j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "                batch_mob = torch.tensor(norm_mob[j*batch_size:(j+1)*batch_size,:][:,j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "                batch_dist = torch.tensor(norm_dist[j*batch_size:(j+1)*batch_size,:][:,j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "                batch_mat = torch.cat([batch_mob.unsqueeze(-1), batch_dist.unsqueeze(-1)], dim=2)\n",
    "                cur_static = [batch_static[:, :4], batch_static[:, 4:9], batch_static[:, 9:14], batch_mat]\n",
    "                \n",
    "                output, _ = model(batch_x, cur_static)\n",
    "                loss = loss_fn(output, batch_y).mean(1).mean()\n",
    "                y_pred += list(output.squeeze().cpu().detach().numpy())\n",
    "                y_true += list(batch_y.squeeze().cpu().detach().numpy())\n",
    "                val_loss.append(loss.item())\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_true = np.array(y_true)\n",
    "        norm_pred = (y_pred * normalize_dict['y'][1]) + normalize_dict['y'][0]\n",
    "        norm_true = (y_true * normalize_dict['y'][1]) + normalize_dict['y'][0]\n",
    "        \n",
    "        cur_mse = mse(norm_true, norm_pred)\n",
    "        cur_mae = mae(norm_true, norm_pred)\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: %d, Train Loss: %.4f, Val Loss: %.4f, MSE: %.2f, MAE: %.2f'%(i, np.mean(epoch_loss), np.mean(val_loss), cur_mse, cur_mae))\n",
    "        if cur_mae < min_loss:\n",
    "            min_loss = cur_mae\n",
    "            min_epoch = i\n",
    "            torch.save(model.state_dict(), './model/hoist_%d.pth'%k)\n",
    "            \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    weight_score = []\n",
    "    batch_size = 128\n",
    "    #Load state dict\n",
    "    model.load_state_dict(torch.load('./model/hoist_%d.pth'%k))\n",
    "    model.eval()\n",
    "\n",
    "    for j in range((len(test_x)//batch_size)+1):\n",
    "        batch_x = test_x[j*batch_size:(j+1)*batch_size]\n",
    "        batch_y = test_y[j*batch_size:(j+1)*batch_size]\n",
    "        batch_x = torch.tensor(batch_x).float().to(device)\n",
    "        batch_y = torch.tensor(batch_y).float().to(device).unsqueeze(-1)\n",
    "        batch_static = torch.tensor(static[j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "        batch_mob = torch.tensor(norm_mob[j*batch_size:(j+1)*batch_size,:][:,j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "        batch_dist = torch.tensor(norm_dist[j*batch_size:(j+1)*batch_size,:][:,j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "        batch_mat = torch.cat([batch_mob.unsqueeze(-1), batch_dist.unsqueeze(-1)], dim=2)\n",
    "        cur_static = [batch_static[:, :4], batch_static[:, 4:9], batch_static[:, 9:14], batch_mat]\n",
    "        output, _ = model(batch_x, cur_static)\n",
    "        \n",
    "        y_pred += list(output.squeeze().cpu().detach().numpy())\n",
    "        y_true += list(batch_y.squeeze().cpu().detach().numpy())\n",
    "        weight_score += list(_[1].squeeze().cpu().detach().numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    weight_score = np.array(weight_score)\n",
    "\n",
    "\n",
    "    norm_pred = (y_pred * normalize_dict['y'][1]) + normalize_dict['y'][0]\n",
    "    norm_true = (y_true * normalize_dict['y'][1]) + normalize_dict['y'][0]\n",
    "    \n",
    "    print('Best Epoch: %d, Test MSE: %.2f, MAE: %.2f, R2: %.2f, CCC: %.2f'%(min_epoch, mse(norm_true, norm_pred), mae(norm_true, norm_pred), r2(norm_true, norm_pred), ccc(norm_true, norm_pred)))\n",
    "    mae_.append(mae(norm_true, norm_pred))\n",
    "    mae_exp.append(mae(np.exp(norm_true), np.exp(norm_pred)))\n",
    "    mse_.append(mse(norm_true, norm_pred))\n",
    "    mse_exp.append(mse(np.exp(norm_true), np.exp(norm_pred)))\n",
    "    r2_.append(r2(norm_true, norm_pred))\n",
    "    r2_exp.append(r2(np.exp(norm_true), np.exp(norm_pred)))\n",
    "    ccc_.append(ccc(norm_true, norm_pred))\n",
    "    ccc_exp.append(ccc(np.exp(norm_true), np.exp(norm_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6785942 0.046414033\n",
      "3845885.5 1018530.6\n",
      "0.61343527 0.015049482\n",
      "368.71564 18.651665\n",
      "0.9020033568009819 0.006827888284309612\n",
      "0.601323965382852 0.1561582756512731\n",
      "0.9537044447544132 0.0037559978775672602\n",
      "0.8909342147884629 0.01898510652806212\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(mse_), np.std(mse_))\n",
    "print(np.mean(mse_exp), np.std(mse_exp))\n",
    "print(np.mean(mae_), np.std(mae_))\n",
    "print(np.mean(mae_exp), np.std(mae_exp))\n",
    "print(np.mean(r2_), np.std(r2_))\n",
    "print(np.mean(r2_exp), np.std(r2_exp))\n",
    "print(np.mean(ccc_), np.std(ccc_))\n",
    "print(np.mean(ccc_exp), np.std(ccc_exp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4aba693b7a99e594578c51987bdc2d5137924281995f291929b38a9b26be41cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
