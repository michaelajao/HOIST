{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "\n",
    "def seed_torch(RANDOM_SEED=123):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_torch()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from utils import generate_series, temporal_split\n",
    "from model import HOIST_without_claim\n",
    "from utils import mse,mae,r2,ccc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_mat = pickle.load(open('./data/mob_mat.pkl', 'rb'))\n",
    "distance_mat = pickle.load(open('./data/distance_mat.pkl', 'rb'))\n",
    "covid_tensor = pickle.load(open('./data/covid_tensor.pkl', 'rb'))\n",
    "hospitalizations = pickle.load(open('./data/hospitalizations.pkl', 'rb'))\n",
    "hos_tensor = pickle.load(open('./data/hos_tensor.pkl', 'rb'))\n",
    "county_tensor = pickle.load(open('./data/county_tensor.pkl', 'rb'))\n",
    "feat_name = pickle.load(open('./data/feat_name.pkl', 'rb'))\n",
    "date_range = np.array(pickle.load(open('./data/date_range.pkl', 'rb')), dtype=np.str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2299\n"
     ]
    }
   ],
   "source": [
    "covid_tensor = np.expand_dims(covid_tensor, axis=2)\n",
    "X = np.concatenate([covid_tensor, hos_tensor], axis=2)\n",
    "y = hospitalizations\n",
    "X, y = generate_series(X, y, window_size=35, pred_size=28)\n",
    "date_idx = np.expand_dims(date_range, axis=0)\n",
    "date_idx = np.expand_dims(date_idx, axis=2)\n",
    "date_idx, _ = generate_series(date_idx, y, window_size=35, pred_size=28, date=True)\n",
    "\n",
    "range_idx = (y.mean(1)>0)\n",
    "county_tensor = county_tensor[range_idx]\n",
    "y = y[range_idx]\n",
    "X = X[range_idx]\n",
    "print(len(y))\n",
    "mob_mat = mob_mat[range_idx, :][:, range_idx]\n",
    "distance_mat = distance_mat[range_idx, :][:, range_idx]\n",
    "\n",
    "y = np.log(y+1)\n",
    "train_x, val_x, test_x, train_y, val_y, test_y, train_idx, val_idx, test_idx, static, mats, normalize_dict, shuffle_idx = temporal_split(X, y, county_tensor, [mob_mat, distance_mat], 0.2, 0.2, norm='min-max', norm_mat=True)\n",
    "\n",
    "norm_mob = mats[0]\n",
    "norm_dist = mats[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.9760, Val Loss: 0.8686, MSE: 5.91, MAE: 2.06\n",
      "Epoch: 100, Train Loss: 1.0583, Val Loss: 0.2447, MSE: 1.67, MAE: 0.99\n",
      "Epoch: 200, Train Loss: 1.0449, Val Loss: 0.2491, MSE: 1.70, MAE: 1.00\n",
      "Best Epoch: 118, Test MSE: 1.84, MAE: 1.06, R2: 0.74, CCC: 0.87\n"
     ]
    }
   ],
   "source": [
    "mae_ = []\n",
    "mae_exp = []\n",
    "mse_ = []\n",
    "mse_exp = []\n",
    "r2_ = []\n",
    "r2_exp = []\n",
    "ccc_ = []\n",
    "ccc_exp = []\n",
    "\n",
    "runs = 1\n",
    "for k in range(runs):\n",
    "    seed_torch(k)\n",
    "    model = HOIST_without_claim(5, [4,5,5], 128, device).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "    loss_fn = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "    epoch = 300\n",
    "    batch_size = 128\n",
    "    min_loss = 1e99\n",
    "    min_epoch = 0\n",
    "\n",
    "    for i in range(epoch):\n",
    "        epoch_loss = []\n",
    "        val_loss = []\n",
    "        model.train()\n",
    "        for j in range((len(test_x)//batch_size)+1):\n",
    "            batch_x = train_x[j*batch_size:(j+1)*batch_size]\n",
    "            batch_y = train_y[j*batch_size:(j+1)*batch_size]\n",
    "            batch_x = torch.tensor(batch_x).float().to(device)\n",
    "            batch_y = torch.tensor(batch_y).float().to(device).unsqueeze(-1)\n",
    "            batch_static = torch.tensor(static[j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "            batch_mob = torch.tensor(norm_mob[j*batch_size:(j+1)*batch_size,:][:,j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "            batch_dist = torch.tensor(norm_dist[j*batch_size:(j+1)*batch_size,:][:,j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "            batch_mat = torch.cat([batch_mob.unsqueeze(-1), batch_dist.unsqueeze(-1)], dim=2)\n",
    "            cur_static = [batch_static[:, :4], batch_static[:, 4:9], batch_static[:, 9:14], batch_mat]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output, _ = model(batch_x, cur_static)\n",
    "            \n",
    "            N, T, F = batch_y.shape\n",
    "            dist = _[0]\n",
    "            weights = _[1]\n",
    "            y_p = (weights * batch_x).sum(-1).reshape(N,T,1)*output.detach()\n",
    "            y_pi = y_p.reshape(N,1,T)\n",
    "            y_pj = y_p.reshape(1,N,T)\n",
    "            y_k = ((y_pi * y_pj) * dist.reshape(N,N,1)).sum(1).reshape(N,T,1)\n",
    "            ising_loss = loss_fn(y_p+y_k, batch_y).mean(1).mean()\n",
    "            \n",
    "            loss = loss_fn(output, batch_y).mean(1).mean() + ising_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(loss.item())\n",
    "        \n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            for j in range((len(test_x)//batch_size)+1):\n",
    "                batch_x = val_x[j*batch_size:(j+1)*batch_size]\n",
    "                batch_y = val_y[j*batch_size:(j+1)*batch_size]\n",
    "                batch_x = torch.tensor(batch_x).float().to(device)\n",
    "                batch_y = torch.tensor(batch_y).float().to(device).unsqueeze(-1)\n",
    "                batch_static = torch.tensor(static[j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "                batch_mob = torch.tensor(norm_mob[j*batch_size:(j+1)*batch_size,:][:,j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "                batch_dist = torch.tensor(norm_dist[j*batch_size:(j+1)*batch_size,:][:,j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "                batch_mat = torch.cat([batch_mob.unsqueeze(-1), batch_dist.unsqueeze(-1)], dim=2)\n",
    "                cur_static = [batch_static[:, :4], batch_static[:, 4:9], batch_static[:, 9:14], batch_mat]\n",
    "                \n",
    "                output, _ = model(batch_x, cur_static)\n",
    "                loss = loss_fn(output, batch_y).mean(1).mean()\n",
    "                y_pred += list(output.squeeze().cpu().detach().numpy())\n",
    "                y_true += list(batch_y.squeeze().cpu().detach().numpy())\n",
    "                val_loss.append(loss.item())\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_true = np.array(y_true)\n",
    "        norm_pred = (y_pred * normalize_dict['y'][1]) + normalize_dict['y'][0]\n",
    "        norm_true = (y_true * normalize_dict['y'][1]) + normalize_dict['y'][0]\n",
    "        \n",
    "        cur_mse = mse(norm_true, norm_pred)\n",
    "        cur_mae = mae(norm_true, norm_pred)\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: %d, Train Loss: %.4f, Val Loss: %.4f, MSE: %.2f, MAE: %.2f'%(i, np.mean(epoch_loss), np.mean(val_loss), cur_mse, cur_mae))\n",
    "        if cur_mae < min_loss:\n",
    "            min_loss = cur_mae\n",
    "            min_epoch = i\n",
    "            torch.save(model.state_dict(), './model/hoist_%d.pth'%k)\n",
    "            \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    weight_score = []\n",
    "    batch_size = 128\n",
    "    #Load state dict\n",
    "    model.load_state_dict(torch.load('./model/hoist_%d.pth'%k))\n",
    "    model.eval()\n",
    "\n",
    "    for j in range((len(test_x)//batch_size)+1):\n",
    "        batch_x = test_x[j*batch_size:(j+1)*batch_size]\n",
    "        batch_y = test_y[j*batch_size:(j+1)*batch_size]\n",
    "        batch_x = torch.tensor(batch_x).float().to(device)\n",
    "        batch_y = torch.tensor(batch_y).float().to(device).unsqueeze(-1)\n",
    "        batch_static = torch.tensor(static[j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "        batch_mob = torch.tensor(norm_mob[j*batch_size:(j+1)*batch_size,:][:,j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "        batch_dist = torch.tensor(norm_dist[j*batch_size:(j+1)*batch_size,:][:,j*batch_size:(j+1)*batch_size]).float().to(device)\n",
    "        batch_mat = torch.cat([batch_mob.unsqueeze(-1), batch_dist.unsqueeze(-1)], dim=2)\n",
    "        cur_static = [batch_static[:, :4], batch_static[:, 4:9], batch_static[:, 9:14], batch_mat]\n",
    "        output, _ = model(batch_x, cur_static)\n",
    "        \n",
    "        y_pred += list(output.squeeze().cpu().detach().numpy())\n",
    "        y_true += list(batch_y.squeeze().cpu().detach().numpy())\n",
    "        weight_score += list(_[1].squeeze().cpu().detach().numpy())\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    weight_score = np.array(weight_score)\n",
    "\n",
    "\n",
    "    norm_pred = (y_pred * normalize_dict['y'][1]) + normalize_dict['y'][0]\n",
    "    norm_true = (y_true * normalize_dict['y'][1]) + normalize_dict['y'][0]\n",
    "    \n",
    "    print('Best Epoch: %d, Test MSE: %.2f, MAE: %.2f, R2: %.2f, CCC: %.2f'%(min_epoch, mse(norm_true, norm_pred), mae(norm_true, norm_pred), r2(norm_true, norm_pred), ccc(norm_true, norm_pred)))\n",
    "    mae_.append(mae(norm_true, norm_pred))\n",
    "    mae_exp.append(mae(np.exp(norm_true), np.exp(norm_pred)))\n",
    "    mse_.append(mse(norm_true, norm_pred))\n",
    "    mse_exp.append(mse(np.exp(norm_true), np.exp(norm_pred)))\n",
    "    r2_.append(r2(norm_true, norm_pred))\n",
    "    r2_exp.append(r2(np.exp(norm_true), np.exp(norm_pred)))\n",
    "    ccc_.append(ccc(norm_true, norm_pred))\n",
    "    ccc_exp.append(ccc(np.exp(norm_true), np.exp(norm_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 5420623.50\n",
      "MAE: 555.40\n",
      "R2: 0.69\n",
      "CCC: 0.79\n"
     ]
    }
   ],
   "source": [
    "print('MSE: %.2f'%np.mean(mse_exp))\n",
    "print('MAE: %.2f'%np.mean(mae_exp))\n",
    "print('R2: %.2f'%np.mean(r2_exp))\n",
    "print('CCC: %.2f'%np.mean(ccc_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
